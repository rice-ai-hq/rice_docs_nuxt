---
title: Working Memory
description: Understanding the attention-based working memory system.
navigation:
  icon: i-lucide-layers
seo:
  title: Working Memory
  description: Learn how Working Memory provides dynamic, attention-based context management for AI agents.
---

Working Memory manages the agent's immediate context. Unlike a raw context window, it is dynamic—items decay over time if not accessed, simulating natural forgetting.

---

## Key Concepts

### Decay

Items naturally decay over time if they aren't accessed. This prevents context overload and ensures the agent focuses on what's currently relevant.

- Recently accessed items stay prominent
- Old, unused items fade away
- No manual cleanup required

### Attention Score

When you read using `drift()`, items are returned sorted by their **Attention Score**—a combination of recency and access frequency.

- High attention: recently added or frequently accessed
- Low attention: old and rarely referenced
- Scores update automatically with each interaction

---

## API Reference

### `focus(content)`

Push information into the agent's attention stream.

**Node.js**

```typescript
await client.focus("User wants to build a React app.");
await client.focus("They prefer TypeScript over JavaScript.");
```

**Python**

```python
client.focus("User wants to build a React app.")
client.focus("They prefer TypeScript over JavaScript.")
```

### `drift()`

Retrieve the current active context, sorted by relevance (Attention Score).

**Node.js**

```typescript
const items = await client.drift();
items.forEach((item) => {
  console.log(`[${item.relevance}] ${item.content}`);
});
```

**Python**

```python
items = client.drift()
for item in items.items:
    print(f"[{item.relevance}] {item.content}")
```

---

## Use Cases

### Conversation Context

Store the active conversation history. Recent exchanges stay prominent while older context naturally fades.

```typescript
// After each user message
await client.focus(`User: ${userMessage}`);
await client.focus(`Assistant: ${response}`);

// Before generating response
const context = await client.drift();
// Pass context to LLM
```

### Task State

Track the current state of a multi-step task.

```typescript
await client.focus("Current step: 3 of 5 - Database setup");
await client.focus("Completed: Project initialization, dependency install");
await client.focus("Next: Configure environment variables");
```

### Scratchpad

Store intermediate thoughts and calculations during reasoning.

```python
client.focus("Considering approach A: More performant but complex")
client.focus("Considering approach B: Simpler but slower")
client.focus("Decision: Going with approach A for the database layer")
```

---

## Best Practices

::callout{icon="i-lucide-lightbulb" color="primary"}
**Keep it focused**: Only add information relevant to the current task. Trust decay to handle cleanup.
::

::callout{icon="i-lucide-clock" color="amber"}
**Don't fight decay**: If something is important long-term, use Episodic Memory instead.
::

::callout{icon="i-lucide-layers" color="blue"}
**Structure your content**: Use consistent formatting for focus items to improve context clarity when passed to the LLM.
::
