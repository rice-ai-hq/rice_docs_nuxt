---
title: "Tutorial 2: Research Assistant Agent"
description: Build a research assistant that synthesizes information and maintains long-term knowledge.
navigation:
  icon: i-lucide-search
seo:
  title: "Building a Research Assistant with Rice Slate"
  description: Comprehensive tutorial on building a research assistant that learns user interests and synthesizes knowledge over time.
---

# Building a Research Assistant Agent

In this tutorial, you'll build an advanced research assistant that:

- Remembers research topics and user interests across sessions
- Synthesizes information from multiple sources
- Builds a personalized knowledge graph over time
- Provides context-aware recommendations
- Tracks research progress and generates summaries

---

## Overview

### The Problem

Researchers and knowledge workers face several challenges:

- **Context Loss**: Starting fresh each session, re-explaining what you're working on
- **Information Silos**: No connection between related research threads
- **No Learning**: The assistant doesn't remember what sources were useful
- **Manual Tracking**: Having to remember what was already covered

### Our Solution

We'll build a cognitive research assistant using Rice Slate:

| Memory Type | Purpose in This Agent |
| :---------- | :-------------------- |
| **Working Memory** | Current research session, active queries, scratchpad notes |
| **Episodic Memory** | Past research sessions, useful sources, synthesis history |
| **Procedural Memory** | Citation formatting, source validation, summary generation |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Research Query                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   1. UNDERSTAND QUERY                        â”‚
â”‚  - Extract research topic and intent                         â”‚
â”‚  - Identify sub-questions                                    â”‚
â”‚  - Detect if this connects to past research                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   2. RECALL CONTEXT                          â”‚
â”‚  Episodic Memory:                                            â”‚
â”‚  - Find related past research sessions                       â”‚
â”‚  - Retrieve user's known interests & preferences             â”‚
â”‚  - Get previously useful sources on this topic               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   3. LOAD SESSION STATE                      â”‚
â”‚  Working Memory:                                             â”‚
â”‚  - Current session notes                                     â”‚
â”‚  - Active research threads                                   â”‚
â”‚  - Pending questions                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   4. RESEARCH & SYNTHESIZE                   â”‚
â”‚  - Search external sources (web, papers, docs)               â”‚
â”‚  - Cross-reference with known information                    â”‚
â”‚  - Generate synthesis with citations                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   5. FORMAT & DELIVER                        â”‚
â”‚  Procedural Memory:                                          â”‚
â”‚  - Format citations properly                                 â”‚
â”‚  - Validate source credibility scores                        â”‚
â”‚  - Structure response for clarity                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   6. LEARN & UPDATE                          â”‚
â”‚  - Record this research session                              â”‚
â”‚  - Update user interest profile                              â”‚
â”‚  - Store useful sources for future reference                 â”‚
â”‚  - Connect to existing knowledge graph                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Setup

### Project Structure

```
research-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py              # Main agent logic
â”‚   â”œâ”€â”€ memory.py             # Rice Slate integration
â”‚   â”œâ”€â”€ llm.py                # LLM client wrapper
â”‚   â”œâ”€â”€ search.py             # External search integration
â”‚   â”œâ”€â”€ models.py             # Pydantic models
â”‚   â””â”€â”€ skills/
â”‚       â”œâ”€â”€ citations.py      # Citation formatting
â”‚       â”œâ”€â”€ validation.py     # Source validation
â”‚       â””â”€â”€ summarize.py      # Summary generation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agent.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

### Dependencies

```bash
# Install Rice Slate Python client
pip install git+https://github.com/rice-ai-hq/rice_slate.git#subdirectory=clients/python

# Create project
mkdir research-assistant && cd research-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install openai httpx pydantic python-dotenv
```

### Environment Variables

```bash
# .env
SLATE_ADDRESS=localhost:50051
SLATE_TOKEN=your-auth-token
OPENAI_API_KEY=your-openai-key
```

---

## Implementation

### Step 1: Define Models

Define clear data structures for our research domain:

```python
# src/models.py

from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime
from enum import Enum


class ResearchIntent(str, Enum):
    EXPLORE = "explore"          # Learning about a new topic
    DEEP_DIVE = "deep_dive"      # Going deeper on known topic
    COMPARE = "compare"          # Comparing multiple things
    VERIFY = "verify"            # Fact-checking
    SUMMARIZE = "summarize"      # Summarizing known information
    CONNECT = "connect"          # Finding relationships


class Source(BaseModel):
    url: str
    title: str
    snippet: str
    credibility_score: float = Field(ge=0, le=1)
    domain: str
    retrieved_at: datetime = Field(default_factory=datetime.now)


class ResearchNote(BaseModel):
    content: str
    topic: str
    sources: List[str] = []
    confidence: float = Field(ge=0, le=1)
    created_at: datetime = Field(default_factory=datetime.now)


class UserInterest(BaseModel):
    topic: str
    strength: float = Field(ge=0, le=1)  # How interested the user is
    depth: float = Field(ge=0, le=1)     # How deep they've gone
    last_accessed: datetime
    related_topics: List[str] = []


class ResearchSession(BaseModel):
    session_id: str
    user_id: str
    primary_topic: str
    queries: List[str] = []
    findings: List[ResearchNote] = []
    sources_used: List[Source] = []
    started_at: datetime = Field(default_factory=datetime.now)
    ended_at: Optional[datetime] = None


class KnowledgeConnection(BaseModel):
    """Represents a link between two concepts in the knowledge graph"""
    from_topic: str
    to_topic: str
    relationship: str  # "related_to", "part_of", "contradicts", "supports"
    strength: float = Field(ge=0, le=1)
    evidence: str
```

### Step 2: Create the Memory Manager

This class manages all Rice Slate interactions with semantic structure:

```python
# src/memory.py

from slate_client import CortexClient
from models import (
    ResearchSession, UserInterest, Source, 
    ResearchNote, KnowledgeConnection
)
from typing import List, Optional, Dict, Any
from datetime import datetime
import json


class ResearchMemory:
    def __init__(self, address: str, token: str):
        self.client = CortexClient(address=address, token=token)
    
    # ============================================
    # WORKING MEMORY - Current session state
    # ============================================
    
    def start_session(self, session_id: str, user_id: str, topic: str) -> None:
        """Initialize a new research session in working memory"""
        self.client.focus(json.dumps({
            "type": "session_start",
            "session_id": session_id,
            "user_id": user_id,
            "primary_topic": topic,
            "started_at": datetime.now().isoformat()
        }))
    
    def add_scratchpad_note(self, session_id: str, note: str, topic: str) -> None:
        """Add a quick note to the session scratchpad"""
        self.client.focus(json.dumps({
            "type": "scratchpad",
            "session_id": session_id,
            "note": note,
            "topic": topic,
            "timestamp": datetime.now().isoformat()
        }))
    
    def add_finding(self, session_id: str, finding: ResearchNote) -> None:
        """Record a research finding"""
        self.client.focus(json.dumps({
            "type": "finding",
            "session_id": session_id,
            **finding.model_dump(mode="json")
        }))
    
    def add_pending_question(self, session_id: str, question: str) -> None:
        """Track a question that came up during research"""
        self.client.focus(json.dumps({
            "type": "pending_question",
            "session_id": session_id,
            "question": question,
            "status": "open",
            "timestamp": datetime.now().isoformat()
        }))
    
    def get_session_context(self) -> List[Dict[str, Any]]:
        """Get all current session context from working memory"""
        items = self.client.drift()
        context = []
        for item in items.items:
            try:
                parsed = json.loads(item.content)
                parsed["relevance"] = item.relevance
                context.append(parsed)
            except json.JSONDecodeError:
                context.append({
                    "type": "text",
                    "content": item.content,
                    "relevance": item.relevance
                })
        return context
    
    def get_session_findings(self, session_id: str) -> List[ResearchNote]:
        """Get all findings from current session"""
        context = self.get_session_context()
        findings = [
            ResearchNote(**{k: v for k, v in item.items() if k != "type" and k != "session_id" and k != "relevance"})
            for item in context 
            if item.get("type") == "finding" and item.get("session_id") == session_id
        ]
        return findings
    
    def get_pending_questions(self, session_id: str) -> List[str]:
        """Get unanswered questions from session"""
        context = self.get_session_context()
        return [
            item["question"]
            for item in context
            if item.get("type") == "pending_question" 
            and item.get("session_id") == session_id
            and item.get("status") == "open"
        ]
    
    # ============================================
    # EPISODIC MEMORY - Past research & learning
    # ============================================
    
    def record_research_session(
        self,
        query: str,
        synthesis: str,
        topics_covered: List[str],
        sources: List[Source],
        user_feedback: Optional[str] = None
    ) -> None:
        """Record a completed research interaction"""
        self.client.commit(
            input=query,
            outcome=synthesis,
            action="research",
            reasoning=json.dumps({
                "topics": topics_covered,
                "source_count": len(sources),
                "sources": [s.model_dump(mode="json") for s in sources[:5]],  # Top 5
                "user_feedback": user_feedback,
                "timestamp": datetime.now().isoformat()
            })
        )
    
    def record_user_interest(
        self,
        user_id: str,
        topic: str,
        interest_signal: str  # "queried", "deep_dived", "bookmarked", "cited"
    ) -> None:
        """Track user interest in a topic for personalization"""
        self.client.commit(
            input=f"user:{user_id} interest:{topic}",
            outcome=interest_signal,
            action="interest_update",
            reasoning=json.dumps({
                "user_id": user_id,
                "topic": topic,
                "signal": interest_signal,
                "timestamp": datetime.now().isoformat()
            })
        )
    
    def record_knowledge_connection(self, connection: KnowledgeConnection) -> None:
        """Record a discovered relationship between topics"""
        self.client.commit(
            input=f"connection:{connection.from_topic}:{connection.to_topic}",
            outcome=connection.relationship,
            action="knowledge_graph",
            reasoning=json.dumps({
                **connection.model_dump(),
                "timestamp": datetime.now().isoformat()
            })
        )
    
    def find_related_research(self, query: str, limit: int = 10) -> List[Dict]:
        """Find past research related to current query"""
        traces = self.client.reminisce(query)
        results = []
        for trace in traces.traces[:limit]:
            try:
                reasoning = json.loads(trace.reasoning) if trace.reasoning else {}
            except json.JSONDecodeError:
                reasoning = {"raw": trace.reasoning}
            
            results.append({
                "original_query": trace.input,
                "synthesis": trace.outcome,
                "action": trace.action,
                "metadata": reasoning
            })
        return results
    
    def get_user_interests(self, user_id: str) -> List[Dict]:
        """Retrieve user's research interests and history"""
        traces = self.client.reminisce(f"user:{user_id} interest:")
        
        # Aggregate interests by topic
        interests: Dict[str, Dict] = {}
        for trace in traces.traces:
            try:
                metadata = json.loads(trace.reasoning) if trace.reasoning else {}
                topic = metadata.get("topic", "unknown")
                signal = metadata.get("signal", "queried")
                
                if topic not in interests:
                    interests[topic] = {
                        "topic": topic,
                        "signals": [],
                        "last_accessed": metadata.get("timestamp")
                    }
                interests[topic]["signals"].append(signal)
            except json.JSONDecodeError:
                continue
        
        # Calculate interest strength
        result = []
        for topic, data in interests.items():
            signal_weights = {
                "queried": 0.1,
                "deep_dived": 0.3,
                "bookmarked": 0.4,
                "cited": 0.5
            }
            strength = min(1.0, sum(signal_weights.get(s, 0.1) for s in data["signals"]))
            result.append({
                **data,
                "strength": strength,
                "depth": len(data["signals"]) / 10  # Normalize by activity
            })
        
        return sorted(result, key=lambda x: x["strength"], reverse=True)
    
    def get_knowledge_graph(self, topic: str) -> List[KnowledgeConnection]:
        """Get connections related to a topic"""
        traces = self.client.reminisce(f"connection:{topic}")
        connections = []
        for trace in traces.traces:
            if trace.action == "knowledge_graph":
                try:
                    data = json.loads(trace.reasoning)
                    connections.append(KnowledgeConnection(**data))
                except (json.JSONDecodeError, ValueError):
                    continue
        return connections
    
    # ============================================
    # PROCEDURAL MEMORY - Deterministic skills
    # ============================================
    
    def format_citation(self, source: Source, style: str = "apa") -> str:
        """Format a source as a citation"""
        # In production, this would call client.trigger("format_citation")
        if style == "apa":
            return f"{source.title}. Retrieved from {source.url}"
        elif style == "mla":
            return f'"{source.title}." Web. {source.retrieved_at.strftime("%d %b %Y")}. <{source.url}>'
        elif style == "chicago":
            return f'{source.title}, accessed {source.retrieved_at.strftime("%B %d, %Y")}, {source.url}.'
        else:
            return f"[{source.title}]({source.url})"
    
    def validate_source(self, source: Source) -> Dict[str, Any]:
        """Validate source credibility"""
        # In production, this would call client.trigger("validate_source")
        
        # Domain credibility scoring
        trusted_domains = {
            "edu": 0.9, "gov": 0.9, "org": 0.7,
            "nature.com": 0.95, "science.org": 0.95,
            "arxiv.org": 0.85, "github.com": 0.7,
            "wikipedia.org": 0.6
        }
        
        domain = source.domain.lower()
        base_score = 0.5
        
        for trusted, score in trusted_domains.items():
            if trusted in domain:
                base_score = score
                break
        
        # Freshness bonus
        days_old = (datetime.now() - source.retrieved_at).days
        freshness_penalty = min(0.2, days_old / 365 * 0.2)
        
        final_score = max(0.1, base_score - freshness_penalty)
        
        return {
            "score": final_score,
            "domain_type": domain.split(".")[-1],
            "is_trusted": final_score >= 0.7,
            "freshness": "fresh" if days_old < 30 else "recent" if days_old < 180 else "dated",
            "recommendation": "cite" if final_score >= 0.6 else "verify" if final_score >= 0.4 else "avoid"
        }
    
    def generate_summary_structure(self, topics: List[str], depth: str = "brief") -> Dict:
        """Generate a structured summary template"""
        # In production, this would call client.trigger("summary_structure")
        
        if depth == "brief":
            return {
                "sections": [
                    {"name": "Overview", "target_words": 100},
                    {"name": "Key Points", "target_words": 150, "format": "bullets"},
                    {"name": "Conclusion", "target_words": 50}
                ],
                "total_target": 300
            }
        elif depth == "detailed":
            sections = [{"name": "Executive Summary", "target_words": 150}]
            for topic in topics:
                sections.append({"name": topic, "target_words": 200})
            sections.extend([
                {"name": "Connections & Implications", "target_words": 150},
                {"name": "Further Research", "target_words": 100, "format": "bullets"},
                {"name": "Sources", "format": "citations"}
            ])
            return {"sections": sections, "total_target": 150 + 200 * len(topics) + 250}
        else:
            return {
                "sections": [
                    {"name": "Summary", "target_words": 500},
                    {"name": "Sources", "format": "citations"}
                ],
                "total_target": 500
            }
```

### Step 3: Create Search Integration

Integrate with external search APIs:

```python
# src/search.py

import httpx
from typing import List, Optional
from models import Source
from datetime import datetime
import os


class SearchClient:
    """Web search integration for research"""
    
    def __init__(self):
        # In production, integrate with real search APIs
        self.api_key = os.getenv("SEARCH_API_KEY", "")
    
    async def search(
        self, 
        query: str, 
        num_results: int = 10,
        domains: Optional[List[str]] = None
    ) -> List[Source]:
        """Search the web for research sources"""
        
        # Simulated search results for tutorial
        # In production, use Google Custom Search, Bing, or Serper
        mock_results = [
            Source(
                url="https://arxiv.org/abs/2301.00001",
                title=f"Research Paper: {query}",
                snippet=f"Academic research on {query} with detailed findings...",
                credibility_score=0.9,
                domain="arxiv.org"
            ),
            Source(
                url=f"https://en.wikipedia.org/wiki/{query.replace(' ', '_')}",
                title=f"{query} - Wikipedia",
                snippet=f"Overview article about {query}...",
                credibility_score=0.6,
                domain="wikipedia.org"
            ),
            Source(
                url="https://github.com/example/repo",
                title=f"Open source implementation: {query}",
                snippet="Implementation and documentation...",
                credibility_score=0.7,
                domain="github.com"
            ),
        ]
        
        if domains:
            mock_results = [r for r in mock_results if any(d in r.domain for d in domains)]
        
        return mock_results[:num_results]
    
    async def search_academic(self, query: str, num_results: int = 5) -> List[Source]:
        """Search academic sources specifically"""
        return await self.search(
            query, 
            num_results, 
            domains=["arxiv.org", "nature.com", "science.org", "edu"]
        )
    
    async def fetch_page_content(self, url: str) -> Optional[str]:
        """Fetch the full content of a page"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(url, follow_redirects=True, timeout=10.0)
                if response.status_code == 200:
                    return response.text[:10000]  # Truncate for safety
        except Exception:
            pass
        return None
```

### Step 4: Create the LLM Client

```python
# src/llm.py

from openai import OpenAI
from typing import List, Dict, Any, Optional
from models import Source, ResearchIntent, ResearchNote
import json


class LLMClient:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def classify_query(self, query: str) -> Dict[str, Any]:
        """Classify the research intent and extract key information"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": """Classify the research query. Return JSON:
{
    "intent": "explore|deep_dive|compare|verify|summarize|connect",
    "primary_topic": "main subject",
    "sub_topics": ["related", "topics"],
    "questions": ["specific questions to answer"],
    "constraints": {"time_period": null, "domain": null, "depth": "brief|moderate|detailed"}
}"""
                },
                {"role": "user", "content": query}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    
    def synthesize_research(
        self,
        query: str,
        sources: List[Source],
        past_research: List[Dict],
        user_interests: List[Dict],
        session_notes: List[str],
        structure: Dict
    ) -> Dict[str, Any]:
        """Synthesize research from multiple sources with context"""
        
        # Build context from past research
        past_context = ""
        if past_research:
            past_context = "\n\nRELATED PAST RESEARCH:\n" + "\n".join([
                f"- Query: {r['original_query']}\n  Finding: {r['synthesis'][:200]}..."
                for r in past_research[:3]
            ])
        
        # Build user interest context
        interest_context = ""
        if user_interests:
            top_interests = user_interests[:5]
            interest_context = "\n\nUSER'S RESEARCH INTERESTS:\n" + ", ".join([
                f"{i['topic']} (depth: {i['depth']:.1f})"
                for i in top_interests
            ])
        
        # Build source context
        source_context = "\n\nSOURCES TO SYNTHESIZE:\n" + "\n".join([
            f"[{i+1}] {s.title} ({s.domain})\n    {s.snippet}"
            for i, s in enumerate(sources)
        ])
        
        # Build session context
        session_context = ""
        if session_notes:
            session_context = "\n\nCURRENT SESSION NOTES:\n" + "\n".join([
                f"- {note}" for note in session_notes[-5:]
            ])
        
        prompt = f"""You are a research assistant synthesizing information for a user.

QUERY: {query}
{past_context}
{interest_context}
{session_context}
{source_context}

REQUIRED STRUCTURE:
{json.dumps(structure, indent=2)}

Provide a comprehensive synthesis that:
1. Directly answers the query
2. Builds on past research when relevant
3. Acknowledges connections to user's interests
4. Cites sources using [1], [2], etc.
5. Highlights any contradictions or gaps
6. Suggests follow-up questions

Return JSON:
{{
    "synthesis": "The full synthesis text with citations",
    "key_findings": ["bullet points"],
    "connections_to_past": ["links to previous research"],
    "knowledge_gaps": ["what's still unknown"],
    "suggested_questions": ["follow-up queries"],
    "confidence": 0.0-1.0,
    "topics_covered": ["list of topics"]
}}"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.7
        )
        
        return json.loads(response.choices[0].message.content)
    
    def extract_connections(
        self,
        topic: str,
        synthesis: str,
        existing_connections: List[Dict]
    ) -> List[Dict]:
        """Extract knowledge graph connections from synthesis"""
        
        existing_str = "\n".join([
            f"- {c['from_topic']} --{c['relationship']}--> {c['to_topic']}"
            for c in existing_connections[:10]
        ]) if existing_connections else "None yet"
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": f"""Extract knowledge connections from the research.

EXISTING CONNECTIONS:
{existing_str}

Return JSON:
{{
    "connections": [
        {{
            "from_topic": "topic A",
            "to_topic": "topic B", 
            "relationship": "related_to|part_of|contradicts|supports|causes|enables",
            "strength": 0.0-1.0,
            "evidence": "brief explanation"
        }}
    ]
}}

Only include high-confidence, meaningful connections."""
                },
                {"role": "user", "content": f"TOPIC: {topic}\n\nSYNTHESIS:\n{synthesis}"}
            ],
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content).get("connections", [])
```

### Step 5: Build the Main Agent

```python
# src/agent.py

import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
import uuid

from memory import ResearchMemory
from llm import LLMClient
from search import SearchClient
from models import Source, ResearchNote, KnowledgeConnection


class ResearchAssistant:
    def __init__(
        self,
        slate_address: str,
        slate_token: str,
        openai_key: str
    ):
        self.memory = ResearchMemory(slate_address, slate_token)
        self.llm = LLMClient(openai_key)
        self.search = SearchClient()
        
        self.current_session_id: Optional[str] = None
        self.current_user_id: Optional[str] = None
    
    def start_session(self, user_id: str, initial_topic: str = "") -> str:
        """Start a new research session"""
        session_id = f"session_{uuid.uuid4().hex[:8]}"
        self.current_session_id = session_id
        self.current_user_id = user_id
        
        self.memory.start_session(session_id, user_id, initial_topic)
        
        print(f"[Agent] Started session {session_id} for user {user_id}")
        return session_id
    
    async def research(self, query: str) -> Dict[str, Any]:
        """Main research method - processes a query and returns synthesis"""
        
        if not self.current_session_id:
            self.start_session("default_user", query.split()[0])
        
        print(f"\n{'='*60}")
        print(f"[Agent] Processing query: {query}")
        print('='*60)
        
        # =========================================
        # STEP 1: UNDERSTAND - Classify the query
        # =========================================
        print("\n[Step 1] Classifying query...")
        classification = self.llm.classify_query(query)
        print(f"  Intent: {classification['intent']}")
        print(f"  Topic: {classification['primary_topic']}")
        print(f"  Sub-topics: {classification.get('sub_topics', [])}")
        
        # Add query to session
        self.memory.add_scratchpad_note(
            self.current_session_id,
            f"Query: {query}",
            classification['primary_topic']
        )
        
        # =========================================
        # STEP 2: RECALL - Get relevant context
        # =========================================
        print("\n[Step 2] Recalling relevant context...")
        
        # Find related past research
        past_research = self.memory.find_related_research(query, limit=5)
        print(f"  Found {len(past_research)} related past research items")
        
        # Get user interests
        user_interests = self.memory.get_user_interests(self.current_user_id)
        print(f"  User has {len(user_interests)} tracked interests")
        
        # Get existing knowledge connections
        connections = self.memory.get_knowledge_graph(classification['primary_topic'])
        print(f"  Found {len(connections)} existing knowledge connections")
        
        # =========================================
        # STEP 3: ORIENT - Load session state
        # =========================================
        print("\n[Step 3] Loading session state...")
        
        session_context = self.memory.get_session_context()
        session_notes = [
            item.get("note", "") 
            for item in session_context 
            if item.get("type") == "scratchpad"
        ]
        print(f"  Session has {len(session_notes)} notes")
        
        pending_questions = self.memory.get_pending_questions(self.current_session_id)
        if pending_questions:
            print(f"  {len(pending_questions)} pending questions from session")
        
        # =========================================
        # STEP 4: RESEARCH - Search and gather
        # =========================================
        print("\n[Step 4] Searching for sources...")
        
        # Determine search strategy based on intent
        if classification['intent'] in ['deep_dive', 'verify']:
            sources = await self.search.search_academic(query, num_results=5)
        else:
            sources = await self.search.search(query, num_results=8)
        
        print(f"  Retrieved {len(sources)} sources")
        
        # Validate sources
        validated_sources = []
        for source in sources:
            validation = self.memory.validate_source(source)
            source.credibility_score = validation['score']
            if validation['recommendation'] != 'avoid':
                validated_sources.append(source)
        
        print(f"  {len(validated_sources)} sources passed validation")
        
        # =========================================
        # STEP 5: SYNTHESIZE - Generate research
        # =========================================
        print("\n[Step 5] Synthesizing research...")
        
        # Get summary structure
        depth = classification.get('constraints', {}).get('depth', 'moderate')
        structure = self.memory.generate_summary_structure(
            classification.get('sub_topics', [classification['primary_topic']]),
            depth=depth
        )
        
        # Generate synthesis
        synthesis_result = self.llm.synthesize_research(
            query=query,
            sources=validated_sources,
            past_research=past_research,
            user_interests=user_interests,
            session_notes=session_notes,
            structure=structure
        )
        
        print(f"  Synthesis complete (confidence: {synthesis_result['confidence']:.2f})")
        print(f"  Key findings: {len(synthesis_result['key_findings'])}")
        
        # =========================================
        # STEP 6: FORMAT - Prepare output
        # =========================================
        print("\n[Step 6] Formatting output...")
        
        # Format citations
        citations = []
        for i, source in enumerate(validated_sources):
            citation = self.memory.format_citation(source, style="apa")
            citations.append(f"[{i+1}] {citation}")
        
        # Build final response
        response = {
            "synthesis": synthesis_result['synthesis'],
            "key_findings": synthesis_result['key_findings'],
            "suggested_questions": synthesis_result['suggested_questions'],
            "knowledge_gaps": synthesis_result['knowledge_gaps'],
            "connections_to_past": synthesis_result['connections_to_past'],
            "citations": citations,
            "confidence": synthesis_result['confidence'],
            "topics_covered": synthesis_result['topics_covered']
        }
        
        # =========================================
        # STEP 7: LEARN - Update memory systems
        # =========================================
        print("\n[Step 7] Recording for future learning...")
        
        # Record the research session
        self.memory.record_research_session(
            query=query,
            synthesis=synthesis_result['synthesis'],
            topics_covered=synthesis_result['topics_covered'],
            sources=validated_sources
        )
        
        # Update user interests
        for topic in synthesis_result['topics_covered']:
            interest_signal = 'deep_dived' if classification['intent'] == 'deep_dive' else 'queried'
            self.memory.record_user_interest(
                self.current_user_id,
                topic,
                interest_signal
            )
        
        # Extract and store knowledge connections
        new_connections = self.llm.extract_connections(
            topic=classification['primary_topic'],
            synthesis=synthesis_result['synthesis'],
            existing_connections=[c.model_dump() for c in connections]
        )
        
        for conn_data in new_connections:
            try:
                connection = KnowledgeConnection(**conn_data)
                self.memory.record_knowledge_connection(connection)
                print(f"  New connection: {connection.from_topic} --{connection.relationship}--> {connection.to_topic}")
            except Exception as e:
                print(f"  Warning: Could not record connection: {e}")
        
        # Store findings in session
        finding = ResearchNote(
            content=synthesis_result['synthesis'][:500],
            topic=classification['primary_topic'],
            sources=[s.url for s in validated_sources[:3]],
            confidence=synthesis_result['confidence']
        )
        self.memory.add_finding(self.current_session_id, finding)
        
        # Add suggested questions as pending
        for question in synthesis_result['suggested_questions'][:3]:
            self.memory.add_pending_question(self.current_session_id, question)
        
        print(f"\n[Agent] Research complete!")
        print(f"  Recorded {len(new_connections)} new knowledge connections")
        print(f"  Added {len(synthesis_result['suggested_questions'][:3])} follow-up questions")
        
        return response
    
    def get_session_summary(self) -> Dict[str, Any]:
        """Get a summary of the current research session"""
        if not self.current_session_id:
            return {"error": "No active session"}
        
        findings = self.memory.get_session_findings(self.current_session_id)
        pending = self.memory.get_pending_questions(self.current_session_id)
        
        return {
            "session_id": self.current_session_id,
            "findings_count": len(findings),
            "pending_questions": pending,
            "topics_covered": list(set(f.topic for f in findings))
        }
    
    def get_user_profile(self) -> Dict[str, Any]:
        """Get the user's research profile"""
        if not self.current_user_id:
            return {"error": "No user set"}
        
        interests = self.memory.get_user_interests(self.current_user_id)
        
        return {
            "user_id": self.current_user_id,
            "top_interests": interests[:10],
            "interest_count": len(interests)
        }
```

### Step 6: Run the Agent

```python
# src/main.py

import asyncio
import os
from dotenv import load_dotenv
from agent import ResearchAssistant

load_dotenv()


async def main():
    # Initialize the agent
    assistant = ResearchAssistant(
        slate_address=os.getenv("SLATE_ADDRESS", "localhost:50051"),
        slate_token=os.getenv("SLATE_TOKEN", ""),
        openai_key=os.getenv("OPENAI_API_KEY", "")
    )
    
    # Start a session
    session_id = assistant.start_session(
        user_id="researcher_alice",
        initial_topic="machine learning"
    )
    
    # First research query
    print("\n" + "="*60)
    print("QUERY 1: Exploring a topic")
    print("="*60)
    
    result1 = await assistant.research(
        "What are the latest developments in transformer architectures for NLP?"
    )
    
    print("\nðŸ“ SYNTHESIS:")
    print(result1['synthesis'][:500] + "...")
    print("\nðŸ” KEY FINDINGS:")
    for finding in result1['key_findings'][:3]:
        print(f"  â€¢ {finding}")
    print("\nâ“ SUGGESTED FOLLOW-UPS:")
    for q in result1['suggested_questions'][:3]:
        print(f"  â€¢ {q}")
    
    # Follow-up query (should use context from first)
    print("\n" + "="*60)
    print("QUERY 2: Following up (should use prior context)")
    print("="*60)
    
    result2 = await assistant.research(
        "How do these compare to traditional RNN approaches for sequence modeling?"
    )
    
    print("\nðŸ“ SYNTHESIS:")
    print(result2['synthesis'][:500] + "...")
    
    if result2['connections_to_past']:
        print("\nðŸ”— CONNECTIONS TO PREVIOUS RESEARCH:")
        for conn in result2['connections_to_past']:
            print(f"  â€¢ {conn}")
    
    # Deep dive query
    print("\n" + "="*60)
    print("QUERY 3: Deep dive on specific aspect")
    print("="*60)
    
    result3 = await assistant.research(
        "I want a detailed technical analysis of attention mechanisms and their computational complexity"
    )
    
    print("\nðŸ“ SYNTHESIS:")
    print(result3['synthesis'][:800] + "...")
    
    # Show session summary
    print("\n" + "="*60)
    print("SESSION SUMMARY")
    print("="*60)
    summary = assistant.get_session_summary()
    print(f"Session: {summary['session_id']}")
    print(f"Findings recorded: {summary['findings_count']}")
    print(f"Topics covered: {summary['topics_covered']}")
    print(f"Pending questions: {len(summary['pending_questions'])}")
    
    # Show user profile
    print("\n" + "="*60)
    print("USER RESEARCH PROFILE")
    print("="*60)
    profile = assistant.get_user_profile()
    print(f"User: {profile['user_id']}")
    print(f"Tracked interests: {profile['interest_count']}")
    print("Top interests:")
    for interest in profile['top_interests'][:5]:
        print(f"  â€¢ {interest['topic']} (strength: {interest['strength']:.2f})")


if __name__ == "__main__":
    asyncio.run(main())
```

---

## How Knowledge Builds Over Time

The power of this agent emerges across sessions:

### Session 1: Initial Exploration

```
User: "What are transformer architectures?"
Agent: [Searches, synthesizes, records]
Memory State:
  - Episodic: Records "transformers" research
  - Working: Current session context
  - Interest: user â†’ transformers (strength: 0.1)
```

### Session 2: Follow-up (days later)

```
User: "How do transformers handle long sequences?"
Agent: [Recalls Session 1] "Building on your previous research on transformers..."
Memory State:
  - Episodic: Finds Session 1 as context
  - Knowledge Graph: transformers â†’ attention â†’ long sequences
  - Interest: user â†’ transformers (strength: 0.4, depth increasing)
```

### Session 10: Deep Expertise

```
User: "Compare sparse attention mechanisms"
Agent: [Rich context from 9 prior sessions]
  - Recalls specific papers user found useful
  - Knows user's depth of knowledge
  - Connects to previous questions about efficiency
Memory State:
  - Knowledge Graph: Dense with connections
  - Interest: user â†’ transformers (strength: 0.9, expert level)
```

---

## Testing

```python
# tests/test_agent.py

import pytest
from src.memory import ResearchMemory
from src.models import Source, KnowledgeConnection
from datetime import datetime


class TestResearchMemory:
    @pytest.fixture
    def memory(self):
        return ResearchMemory("localhost:50051", "test-token")
    
    def test_source_validation_trusted_domain(self, memory):
        source = Source(
            url="https://arxiv.org/abs/2301.00001",
            title="Test Paper",
            snippet="Test",
            credibility_score=0,
            domain="arxiv.org"
        )
        result = memory.validate_source(source)
        assert result['score'] >= 0.8
        assert result['is_trusted'] == True
        assert result['recommendation'] == 'cite'
    
    def test_source_validation_untrusted_domain(self, memory):
        source = Source(
            url="https://random-blog.com/post",
            title="Blog Post",
            snippet="Opinion",
            credibility_score=0,
            domain="random-blog.com"
        )
        result = memory.validate_source(source)
        assert result['score'] < 0.7
        assert result['recommendation'] in ['verify', 'avoid']
    
    def test_citation_formatting_apa(self, memory):
        source = Source(
            url="https://example.com/paper",
            title="Important Research",
            snippet="...",
            credibility_score=0.9,
            domain="example.com"
        )
        citation = memory.format_citation(source, style="apa")
        assert "Important Research" in citation
        assert "example.com/paper" in citation
    
    def test_summary_structure_brief(self, memory):
        structure = memory.generate_summary_structure(["AI", "ML"], depth="brief")
        assert len(structure['sections']) == 3
        assert structure['total_target'] == 300
    
    def test_summary_structure_detailed(self, memory):
        structure = memory.generate_summary_structure(["AI", "ML"], depth="detailed")
        assert len(structure['sections']) > 3
        assert any(s['name'] == 'AI' for s in structure['sections'])
```

---

## Enhancements

### 1. Research Timeline

Track how understanding evolves:

```python
async def get_research_timeline(self, topic: str) -> List[Dict]:
    """Get the progression of research on a topic"""
    related = self.memory.find_related_research(topic, limit=50)
    # Sort by timestamp, show evolution of understanding
    return sorted(related, key=lambda x: x['metadata'].get('timestamp', ''))
```

### 2. Contradiction Detection

Flag conflicting information:

```python
async def detect_contradictions(self, new_finding: str) -> List[Dict]:
    """Check if new finding contradicts existing knowledge"""
    past = self.memory.find_related_research(new_finding)
    # Use LLM to identify contradictions
    # Return list of conflicting prior findings
```

### 3. Research Recommendations

Proactively suggest research directions:

```python
async def suggest_research_directions(self) -> List[str]:
    """Suggest topics based on knowledge gaps"""
    interests = self.memory.get_user_interests(self.current_user_id)
    graph = self.memory.get_knowledge_graph(interests[0]['topic'])
    # Identify sparse areas of the graph
    # Suggest queries to fill gaps
```

### 4. Collaborative Research

Share knowledge across users:

```python
async def find_related_researchers(self, topic: str) -> List[Dict]:
    """Find other users researching similar topics"""
    # Query episodic memory across users (with permissions)
    # Enable knowledge sharing and collaboration
```

---

## Summary

In this tutorial, you built a research assistant that:

- âœ… Maintains session context with **Working Memory**
- âœ… Learns from past research with **Episodic Memory**
- âœ… Validates sources and formats citations with **Procedural Memory**
- âœ… Builds a personal knowledge graph over time
- âœ… Tracks user interests for personalization
- âœ… Improves synthesis quality with accumulated context

The agent demonstrates how Rice Slate enables true long-term learning and personalization across sessions.

::callout{icon="i-lucide-lightbulb" color="primary"}
**Key Insight**: The value of this agent compounds over time. Each research session enriches the knowledge graph, making future research more contextual and personalized.
::

---

## Next Steps

You've now completed both tutorials. Here are ideas for combining them:

1. **Research-Powered Support**: Give your support agent access to a knowledge base that learns
2. **Multi-Agent Systems**: Have the research assistant feed insights to the support agent
3. **Feedback Loops**: Use support interactions to identify research gaps

Explore the [API Reference](/guides/connecting) for detailed method documentation.
